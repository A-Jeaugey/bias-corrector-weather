import os
import pandas as pd
from joblib import dump
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.inspection import permutation_importance

from config import FORECASTS_CSV, OBS_CSV
from features import prepare_merged


def entrainer_modele_pour_variable(dataframe_fusionne: pd.DataFrame, variable_cible: str):
    """
    Entra√Æne un mod√®le de gradient boosting histogramme pour une variable cible donn√©e
    (par exemple temp√©rature maximale ou minimale), en apprenant √† pr√©dire l'erreur
    entre la pr√©vision brute et l'observation r√©elle.

    Args:
        dataframe_fusionne (pd.DataFrame): tableau contenant les pr√©visions,
                                        les observations et les variables explicatives.
        variable_cible (str): "tmax" ou "tmin"

    Returns:
        modele (HistGradientBoostingRegressor): mod√®le entra√Æn√©
        erreur_holdout (float|None): erreur absolue moyenne sur les 15 derniers jours simul√©s
                                     ou None s‚Äôil n‚Äôy a pas assez de donn√©es.
    """
    colonne_erreur = f"err_{variable_cible}"

    # S√©lection dynamique des colonnes explicatives (features)
    colonnes_jour_semaine = [col for col in dataframe_fusionne.columns if col.startswith("dow_")]
    colonnes_explicatives = [
        f"{variable_cible}_prev",  # valeur pr√©vue brute
        "doy_sin", "doy_cos",      # saisonnalit√©
        "prcp_prev", "ws_prev"     # pluie et vent
    ] + colonnes_jour_semaine

    X = dataframe_fusionne[colonnes_explicatives]
    y = dataframe_fusionne[colonne_erreur]

    # Entra√Ænement du mod√®le principal
    modele = HistGradientBoostingRegressor(
        max_iter=300,
        learning_rate=0.05,
        max_depth=None,
        random_state=42
    )
    modele.fit(X, y)

    # Importance des variables (permutation)
    resultat_importances = permutation_importance(
        modele, X, y, n_repeats=10, random_state=42, n_jobs=-1
    )
    valeurs_importance = resultat_importances.importances_mean
    indices_tries = valeurs_importance.argsort()[::-1]

    print(f"\n[üìà] Importance des variables (permutation) pour {variable_cible} :")
    for indice in indices_tries:
        print(f"  - {colonnes_explicatives[indice]} : {valeurs_importance[indice]:.4f}")

    # √âvaluation sur les 15 derniers jours (split temporel)
    erreur_holdout = None
    if len(dataframe_fusionne) > 30:
        donnees_apprentissage = dataframe_fusionne.iloc[:-15]
        donnees_test = dataframe_fusionne.iloc[-15:]

        modele_temporaire = HistGradientBoostingRegressor(
            max_iter=300,
            learning_rate=0.05,
            max_depth=None,
            random_state=42
        )
        modele_temporaire.fit(
            donnees_apprentissage[colonnes_explicatives],
            donnees_apprentissage[colonne_erreur]
        )

        prediction_corrigee = (
            donnees_test[f"{variable_cible}_prev"] +
            modele_temporaire.predict(donnees_test[colonnes_explicatives])
        )

        erreur_holdout = mean_absolute_error(
            donnees_test[f"{variable_cible}_obs"],
            prediction_corrigee
        )

    return modele, erreur_holdout


def main():
    # Chargement des donn√©es de pr√©visions et d'observations
    tableau_previsions = pd.read_csv(FORECASTS_CSV)
    tableau_observations = pd.read_csv(OBS_CSV)

    # Fusion et enrichissement avec les variables explicatives
    tableau_fusionne = prepare_merged(tableau_previsions, tableau_observations)
    tableau_fusionne = tableau_fusionne.sort_values("date")

    # Cr√©ation du dossier de sauvegarde des mod√®les
    os.makedirs("models", exist_ok=True)

    # Entra√Ænement pour la temp√©rature maximale
    modele_tmax, erreur_tmax = entrainer_modele_pour_variable(tableau_fusionne, "tmax")

    # Entra√Ænement pour la temp√©rature minimale
    modele_tmin, erreur_tmin = entrainer_modele_pour_variable(tableau_fusionne, "tmin")

    # Sauvegarde des mod√®les entra√Æn√©s
    dump(modele_tmax, "models/hgb_tmax.joblib")
    dump(modele_tmin, "models/hgb_tmin.joblib")

    print("\n[OK] Mod√®les HistGradientBoosting enregistr√©s avec succ√®s.")
    if erreur_tmax is not None:
        print(f"Erreur MAE (tmax_corr) = {erreur_tmax:.2f} ¬∞C sur les 15 derniers jours simul√©s.")
    if erreur_tmin is not None:
        print(f"Erreur MAE (tmin_corr) = {erreur_tmin:.2f} ¬∞C sur les 15 derniers jours simul√©s.")


if __name__ == "__main__":
    main()
